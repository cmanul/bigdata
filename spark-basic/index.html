<!DOCTYPE html>
<html lang="en">

<head>

    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="description" content="Gatech CSE big data bootcamp">
    <title>Spark Basic - Bigdata Bootcamp</title>

    <link rel="canonical" href="http://www.sunlab.org/bigdata/spark-basic/">
    <!-- favicon -->
    <link rel="icon" type="image/png" sizes="100x60" href="/bigdata/image/favicon.png">

    <!-- Bootstrap Core CSS -->
    <link rel="stylesheet" href="/bigdata/css/bootstrap.min.css">

    <!-- Custom CSS -->
    <link rel="stylesheet" href="/bigdata/css/bigdata-bootcamp.min.css">

    <!-- Pygments Github CSS -->
    <link rel="stylesheet" href="/bigdata/css/syntax.css">

    <!-- TOC -->
    <link rel="stylesheet" href="/bigdata/css/jquery.tocify.css">


    <!-- Custom Fonts -->
    <link href="//maxcdn.bootstrapcdn.com/font-awesome/4.3.0/css/font-awesome.min.css" rel="stylesheet" type="text/css">
    <link href='//fonts.googleapis.com/css?family=Lora:400,700,400italic,700italic' rel='stylesheet' type='text/css'>
    <link href='//fonts.googleapis.com/css?family=Open+Sans:300italic,400italic,600italic,700italic,800italic,400,300,600,700,800' rel='stylesheet' type='text/css'>

    <!-- HTML5 Shim and Respond.js IE8 support of HTML5 elements and media queries -->
    <!-- WARNING: Respond.js doesn't work if you view the page via file:// -->
    <!--[if lt IE 9]>
        <script src="https://oss.maxcdn.com/libs/html5shiv/3.7.0/html5shiv.js"></script>
        <script src="https://oss.maxcdn.com/libs/respond.js/1.4.2/respond.min.js"></script>
    <![endif]-->

</head>


<body>

    <!-- Navigation -->
<nav class="navbar navbar-default navbar-custom navbar-fixed-top" style="z-index:100">
    <div class="container-fluid">
        <!-- Brand and toggle get grouped for better mobile display -->
        <div class="navbar-header page-scroll">
            <button type="button" class="navbar-toggle" data-toggle="collapse" data-target="#bs-example-navbar-collapse-1">
                <span class="sr-only">Toggle navigation</span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
            </button>
            <a class="navbar-brand" href="/bigdata/">Bigdata Bootcamp</a>
        </div>

        <!-- Collect the nav links, forms, and other content for toggling -->
        <div class="collapse navbar-collapse" id="bs-example-navbar-collapse-1">
            <ul class="nav navbar-nav navbar-right">
<!--                 <li>
                    <a href="/bigdata/">Home</a>
                </li> -->
                <li>
                    <a href="/bigdata/contact/">Contact us</a>
                </li>
<!--                 <li>
                    <a href="/bigdata/spark/">Spark</a>
                </li> -->
<!--                 <li>
                    <a href="/bigdata/hadoop/">Hadoop</a>
                </li> -->
            </ul>
            <ul class="nav navbar-nav navbar-left">
                <li>
                    <a href="/bigdata/">Home</a>
                </li>
<!--                 <li>
                    <a href="/bigdata/about/">About</a>
                </li> -->
                <li>
                    <a href="/bigdata/hadoop/">Hadoop</a>
                </li>
                <li>
                    <a href="/bigdata/spark/">Spark</a>
                </li>
                <li><a href="/bigdata/environment/">Environment</a></li>
                <li><a href="/bigdata/data/">Data</a></li>
            </ul>
        </div>
        <!-- /.navbar-collapse -->
    </div>
    <!-- /.container -->
</nav>


    <!-- Page Header -->
<header class="intro-header" style="background-image: url('/bigdata/image/background.jpg')">
    <div class="container">
        <div class="row">
            <div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1">
                <div class="site-heading" style="padding: 100px 0px 50px 0px">
                    <h1>Spark Basic</h1>
                    <hr class="small">
                    <span class="subheading">Georgia Tech big data bootcamp training material</span>
                </div>
            </div>
        </div>
    </div>
</header>

<!-- Main Content -->
<div class="container">
    <div class="row">
        <div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1">
            <ul class="pager">
                
  
  

  
  

  
  

  
  

  
  

  
  

  
  

  
  

  
  

  
    
  
  

  
  

  
  

  
  



<li class="previous">
    <a href="/bigdata/scala-basic/" data-toggle="tooltip" data-placement="top" title="Previous Lesson">&larr; Scala Basic</a>
</li>

                
  
    
  

  
    
  

  
    
  

  
    
  

  
    
  

  
    
  

  
    
  

  
    
  

  
    
  

  
    
      
    
  

  
    
    
  

  
    
  

  
    
  



<li class="next">
    <a href="/bigdata/spark-sql/" data-toggle="tooltip" data-placement="top" title="Next Lesson">Spark Sql&rarr;</a>
</li>


            </ul>

            <div class="bs-callout bs-callout-info" id="callout-helper-context-color-specificity">
        <h4>Learning Objectives</h4><ul>
<li>Invoking command in Spark interactive shell.</li>
<li>Familiar with RDD concept.</li>
<li>Know basic RDD operations.</li>
</ul>
</div>

<h1 id="spark-shell">Spark Shell</h1>

<p>Start the Spark interactive shell by invoking <code class="prettyprint">spark-shell</code> in terminal. Then you will see</p>
<div class="highlight"><pre><code class="language-text" data-lang="text">&gt; spark-shell
Using Spark&#39;s default log4j profile: org/apache/spark/log4j-defaults.properties
...
[messages]
...
Spark context available as sc.
scala&gt;
</code></pre></div>
<p>In Spark, we call the main entrance of program the driver. Here in interactive shell, the Spark shell program is driver. A driver program can access Spark through a <code class="prettyprint">SparkContext</code> object, which represents a connection to a computing cluster. In above interactive shell, <code class="prettyprint">SparkContext</code> is already created for you as variable <code class="prettyprint">sc</code>. You can input <code class="prettyprint">sc</code> to see its type.</p>
<div class="highlight"><pre><code class="language-text" data-lang="text">scala&gt; sc
res0: org.apache.spark.SparkContext = org.apache.spark.SparkContext@27896d3b
</code></pre></div>
<h1 id="rdd">RDD</h1>

<p>Resilient Distributed Dataset(RDD) is Spark&#39;s core abstraction for working with data. An RDD is simply a fault-tolerant <strong>distributed</strong> collection of elements. In Spark, all work is expressed as either creating new RDDs, transforming existing RDDs, or calling operations on RDDs to compute a result. There are two ways to create RDDs: by distributing a collection of objects (e.g., a list or set), or by referencing a dataset in an external storage system, such as a shared filesystem, HDFS, HBase, or any data source offering a Hadoop InputFormat.</p>

<h2 id="parallelized-collections">Parallelized Collections</h2>

<p>The simplest way to create an RDD is to take an existing collection (a Scala Seq) in your program and pass it to SparkContext&#39;s <code class="prettyprint">parallelize()</code> method.</p>
<div class="highlight"><pre><code class="language-scala" data-lang="scala">scala&gt; val data = Array(1, 2, 3, 4, 5)
data: Array[Int] = Array(1, 2, 3, 4, 5)

scala&gt; val distData = sc.parallelize(data)
distData: org.apache.spark.rdd.RDD[Int] = ParallelCollectionRDD[2] at parallelize at &lt;console&gt;:23
</code></pre></div>
<p>Once created, the distributed dataset (distData) can be operated on in parallel. For example, we can add up the elements by calling <code class="prettyprint">distData.reduce((a, b) =&gt; a + b)</code>. You will see more operations on RDD later on.</p>

<div class="msgbox bg-warning"><h4>Warning</h4><p>Parallelizing a collection is very useful when you are learning Spark. However, this is not encouraged in real practice since it requires the entire dataset to be in memory of driver program first. Instead, importing data from <a href="#external-datasets">external datasets</a> should be employed.</p>
</div>

<h2 id="external-datasets">External Datasets</h2>

<p>A more common way to create RDDs is to load data from external storage. Below we show how to load data from your local file system.</p>
<div class="highlight"><pre><code class="language-scala" data-lang="scala">scala&gt; val lines = sc.textFile(&quot;case.csv&quot;)
lines: org.apache.spark.rdd.RDD[String] = README.md MapPartitionsRDD[1] at textFile at &lt;console&gt;:21
</code></pre></div>
<p>Here in above example, each line of the original file will become an element in the <code class="prettyprint">lines</code> RDD.</p>

<div class="msgbox bg-info"><h4>Information</h4><p>Reading data from file syetem, Spark relies on HDFS library. In above example we didn&#39;t configure HDFS through environmental viarable or configuration file so that data is read from local file system. </p>
</div>

<h1 id="rdd-operations">RDD Operations</h1>

<p>RDDs offer two types of operations: <strong>transformation</strong> and <strong>actions</strong>:</p>

<ul>
<li><strong>Transformations</strong> are operations on RDDs that return a new RDD, such as <code class="prettyprint">map()</code> and <code class="prettyprint">filter()</code>.</li>
<li><strong>Actions</strong> are operations that return a result to the driver program or write it to storage, such as <code class="prettyprint">first()</code> and <code class="prettyprint">count()</code>.</li>
</ul>

<p>Spark treats <strong>transformations</strong> and <strong>actions</strong> very differently, so understanding which type of operation you are performing is very important.
You can check whether a function is a transformation or an action by looking at its return type: <strong>transformations</strong> return RDDs, whereas <strong>actions</strong> return some other data type.</p>

<p>All <strong>transformations</strong> in Spark are lazy, in that they do not compute the results right away. Instead, they just remember the operations applied to some base dataset (e.g. an Array or a file). The <strong>transformations</strong> are only computed when an action requires a result to be returned to the driver program.
Therefore, the above command of reading in a file has not actually been executed yet. 
We can force the evaluation of RDDs by calling any <strong>actions</strong>.</p>

<p>Let&#39;s go through some common RDD operations by playing with our dataset.
Recall that in the file <strong>case.csv</strong>, each line is a 4-filed tuple <code class="prettyprint">(patient-id, event-id, timestamp, value)</code>.</p>

<h2 id="count">Count</h2>

<p>We can count the number of lines in the input file using <code class="prettyprint">count</code> operation, i.e.</p>
<div class="highlight"><pre><code class="language-scala" data-lang="scala">scala&gt; lines.count()
res1: Long = 14046
</code></pre></div>
<p>Clearly, <code class="prettyprint">count</code> is an <strong>action</strong>.</p>

<h2 id="take">Take</h2>

<p>Let us take a peek at the data. The <code class="prettyprint">take(k)</code> will return the first k elements in the RDD. Spark also provides <code class="prettyprint">collect()</code> which brings all the elements in the RDD back to the driver program. Note that it is only used when the data is small. Both <code class="prettyprint">take</code> and <code class="prettyprint">collect</code> are <strong>actions</strong>.</p>
<div class="highlight"><pre><code class="language-scala" data-lang="scala">scala&gt; lines.take(5)
res2: Array[String] = Array(00013D2EFD8E45D1,DIAG78820,1166,1.0, 00013D2EFD8E45D1,DIAGV4501,1166,1.0, 00013D2EFD8E45D1,heartfailure,1166,1.0, 00013D2EFD8E45D1,DIAG2720,1166,1.0, 00013D2EFD8E45D1,DIAG4019,1166,1.0)  
</code></pre></div>
<p>We got the first 5 records in this RDD. However, this is hard to read. We can make it more readable by traversing the array to print each record on its own line. </p>
<div class="highlight"><pre><code class="language-scala" data-lang="scala">scala&gt; lines.take(5).foreach(println)
00013D2EFD8E45D1,DIAG78820,1166,1.0
00013D2EFD8E45D1,DIAGV4501,1166,1.0
00013D2EFD8E45D1,heartfailure,1166,1.0
00013D2EFD8E45D1,DIAG2720,1166,1.0
00013D2EFD8E45D1,DIAG4019,1166,1.0
</code></pre></div>
<p>Note that during the above 3 commands, the RDD <code class="prettyprint">lines</code> has been computed (i.e. read in from file) 3 times. We can prevent this by calling <code class="prettyprint">lines.cache()</code>, which will cache the RDD in memory.</p>

<h2 id="map">Map</h2>

<p>The <code class="prettyprint">map</code> operation in Spark is similar to that of Hadoop. It&#39;s a <strong>transformation</strong> that transforms each item in the RDD into a new item by performing the provided function. For example, in order to get IDs of loaded patients, we use <code class="prettyprint">map</code> like</p>
<div class="highlight"><pre><code class="language-scala" data-lang="scala">scala&gt; lines.map(line =&gt; line.split(&quot;,&quot;)(0))
</code></pre></div>
<h2 id="filter">Filter</h2>

<p>As indicated by it&#39;s name, <code class="prettyprint">filter</code> can <strong>transform</strong> an RDD to another by filtering out elements that satisfy given condition. For example, we can count the number of records for a particular patients by using the <code class="prettyprint">filter</code> function.</p>
<div class="highlight"><pre><code class="language-scala" data-lang="scala">scala&gt; lines.filter(line =&gt; line.contains(&quot;00013D2EFD8E45D1&quot;)).count()
res4: Long = 200
</code></pre></div>
<h2 id="distinct">Distinct</h2>

<p><code class="prettyprint">distinct</code> is a <code class="prettyprint">transformation</code> that transform a RDD to another by eliminating duplications. We can use that to calculate the number of distinct patients. In order to do this, we first extract the patient ID from each line.
We use the <code class="prettyprint">map()</code> function, In this example, we transform each line into the corresponding patient ID by extracting only the first column. We then eliminate duplicate IDs by the <code class="prettyprint">distinct()</code> function.</p>
<div class="highlight"><pre><code class="language-scala" data-lang="scala">scala&gt; lines.map(line =&gt; line.split(&quot;,&quot;)(0)).distinct().count()
res5: Long = 100
</code></pre></div>
<h2 id="reduce">Reduce</h2>

<p>Spark provides a similar operation of reduce in MapReduce, <code class="prettyprint">reduceByKey</code>. This name is more informative. It <em>transform</em> an <code class="prettyprint">RDD[(K, V)]</code> into <code class="prettyprint">RDD[(K, List[V])]</code> and aggregate on <code class="prettyprint">List[V]</code> to get <code class="prettyprint">RDD[(K, V)]</code>. Suppose now we want to calculate the total payment by each patients. A payment record in the dataset is in the form of <code class="prettyprint">(patient-id, PAYMENT, timestamp, value)</code>.</p>
<div class="highlight"><pre><code class="language-scala" data-lang="scala">scala&gt; val payments = lines.filter(line =&gt; line.contains(&quot;PAYMENT&quot;)).
                                 map{ x =&gt;
                                   val s = x.split(&quot;,&quot;)
                                   (s(0), s(3).toFloat)
                                 }.reduceByKey(_+_)
</code></pre></div>
<p>The RDD returned by <code class="prettyprint">filter</code> contains those records associated with payment. Each item is then transformed to a key-value pair <code class="prettyprint">(patient-id, amount)</code> with <code class="prettyprint">map</code>. Because each patient can have multiple payments, we need to use <code class="prettyprint">reduceByKey</code> to sum up the payments for each patient. Here in this example, <code class="prettyprint">patient-id</code> will be key, and <code class="prettyprint">amount</code> be value to aggregate.</p>

<p>We can then show the top-3 patients with the highest payment using <code class="prettyprint">sortBy</code> first.</p>
<div class="highlight"><pre><code class="language-scala" data-lang="scala">scala&gt; payments.sortBy(_._2, false).take(3).foreach(println)
</code></pre></div><div class="highlight"><pre><code class="language-text" data-lang="text">(0085B4F55FFA358D,139880.0)
(019E4729585EF3DD,108980.0)
(01AC552BE839AB2B,108530.0)
</code></pre></div>
<h2 id="statistics">Statistics</h2>

<p>For RDD consists of numeric values, Spark provides some useful statistical primitives.</p>
<div class="highlight"><pre><code class="language-scala" data-lang="scala">scala&gt; val payment_values = payments.map(payment =&gt; payment._2).cache()
scala&gt; payment_values.max()
res6: Float = 139880.0

scala&gt; payment_values.min()
res7: Float = 3910.0

scala&gt; payment_values.sum()
res8: Double = 2842480.0

scala&gt; payment_values.mean()
res9: Double = 28424.8  

scala&gt; payment_values.stdev()
res10: Double = 26337.091771112468
</code></pre></div>
<h2 id="set-operation">Set Operation</h2>

<p>RDDs support many of the operations of mathematical sets, such as <code class="prettyprint">union</code> and <code class="prettyprint">intersection</code>, even when the RDDs themselves are not properly sets. For example, we can combine the two files by the <code class="prettyprint">union</code> fucntion. Please notice that <code class="prettyprint">union</code> here is not strictly identical to union operation in mathmatics as Spark will not remove duplication.</p>
<div class="highlight"><pre><code class="language-scala" data-lang="scala">scala&gt; val lines2 = sc.textFile(&quot;control.csv&quot;)
scala&gt; lines.union(lines2).count() 
res11: Long = 31144 

</code></pre></div>
<h1 id="further-reading">Further Reading</h1>

<p>For the complete list of RDD operations, please see the 
<a href="https://spark.apache.org/docs/latest/programming-guide.html#rdd-operations">Spark Programming Guide</a>.</p>


            <ul class="pager">
                
  
  

  
  

  
  

  
  

  
  

  
  

  
  

  
  

  
  

  
    
  
  

  
  

  
  

  
  



<li class="previous">
    <a href="/bigdata/scala-basic/" data-toggle="tooltip" data-placement="top" title="Previous Lesson">&larr; Scala Basic</a>
</li>

                
  
    
  

  
    
  

  
    
  

  
    
  

  
    
  

  
    
  

  
    
  

  
    
  

  
    
  

  
    
      
    
  

  
    
    
  

  
    
  

  
    
  



<li class="next">
    <a href="/bigdata/spark-sql/" data-toggle="tooltip" data-placement="top" title="Next Lesson">Spark Sql&rarr;</a>
</li>


            </ul>

            <div class="clearfix"></div>

            <hr>
            <!-- disqus -->
            <div id="disqus_thread"></div>
            <script type="text/javascript">
                /* * * CONFIGURATION VARIABLES * * */
                var disqus_shortname = 'sunlabbigdata';
                
                /* * * DON'T EDIT BELOW THIS LINE * * */
                (function() {
                    var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
                    dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
                    (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
                })();
            </script>
            <noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript" rel="nofollow">comments powered by Disqus.</a></noscript>
        </div>
        <div class="col-lg-2 col-md-1">
            <div id="toc"></div>
        </div>
    </div>
</div>

<hr>



    <!-- Footer -->
<footer>
    <div class="container">
        <div class="row">
            <div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1">
                <ul class="list-inline text-center">
                    <li>
                        <a href="/bigdata/feed.xml" target="_blank">
                            <span class="fa-stack fa-lg">
                                <i class="fa fa-circle fa-stack-2x"></i>
                                <i class="fa fa-rss fa-stack-1x fa-inverse"></i>
                            </span>
                        </a>
                    </li>
                    
                    <li>
                        <a href="https://twitter.com/jimeng" target="_blank">
                            <span class="fa-stack fa-lg">
                                <i class="fa fa-circle fa-stack-2x"></i>
                                <i class="fa fa-twitter fa-stack-1x fa-inverse"></i>
                            </span>
                        </a>
                    </li>
                    
                    
                    <li>
                        <a href="https://www.facebook.com/cmanul" target="_blank">
                            <span class="fa-stack fa-lg">
                                <i class="fa fa-circle fa-stack-2x"></i>
                                <i class="fa fa-facebook fa-stack-1x fa-inverse"></i>
                            </span>
                        </a>
                    </li>
                    
                    
                    <li>
                        <a href="https://github.com/cmanul" target="_blank">
                            <span class="fa-stack fa-lg">
                                <i class="fa fa-circle fa-stack-2x"></i>
                                <i class="fa fa-github fa-stack-1x fa-inverse"></i>
                            </span>
                        </a>
                    </li>
                    
                </ul>
                <p class="copyright text-muted">Copyright &copy; Georgia Institute of Technology 2015. Theme by <a href="https://github.com/IronSummitMedia/startbootstrap-clean-blog-jekyll" target="_blank">Iron Summit Media</a>'s Jekyll version of <a href="http://startbootstrap.com/template-overviews/clean-blog/" target="_blank">Clean Blog</a>.</p>
            </div>
        </div>
    </div>
</footer>

<!-- jQuery -->
<script src="/bigdata/js/jquery.min.js "></script>

<!-- Bootstrap Core JavaScript -->
<script src="/bigdata/js/bootstrap.min.js "></script>

<!-- TOC -->
<script src="/bigdata/js/jquery-ui.min.js"></script>
<script src="/bigdata/js/jquery.tocify.js"></script>

<!-- ACE Editor -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/ace/1.2.0/ace.js" type="text/javascript" charset="utf-8"></script>

<!-- Custom Theme JavaScript -->
<script src="/bigdata/js/bigdata-bootcamp.js "></script>


</body>

</html>
