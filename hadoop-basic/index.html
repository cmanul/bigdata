<!DOCTYPE html>
<html lang="en">

<head>

    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="description" content="Gatech CSE big data bootcamp">
    <title>Hadoop Basic - Bigdata Bootcamp</title>

    <link rel="canonical" href="http://www.sunlab.org/bigdata/hadoop-basic/">
    <!-- favicon -->
    <link rel="icon" type="image/png" sizes="100x60" href="/bigdata/image/favicon.png">

    <!-- Bootstrap Core CSS -->
    <link rel="stylesheet" href="/bigdata/css/bootstrap.min.css">

    <!-- Custom CSS -->
    <link rel="stylesheet" href="/bigdata/css/bigdata-bootcamp.min.css">

    <!-- Pygments Github CSS -->
    <link rel="stylesheet" href="/bigdata/css/syntax.css">

    <!-- TOC -->
    <link rel="stylesheet" href="/bigdata/css/jquery.tocify.css">


    <!-- Custom Fonts -->
    <link href="//maxcdn.bootstrapcdn.com/font-awesome/4.3.0/css/font-awesome.min.css" rel="stylesheet" type="text/css">
    <link href='//fonts.googleapis.com/css?family=Lora:400,700,400italic,700italic' rel='stylesheet' type='text/css'>
    <link href='//fonts.googleapis.com/css?family=Open+Sans:300italic,400italic,600italic,700italic,800italic,400,300,600,700,800' rel='stylesheet' type='text/css'>

    <!-- HTML5 Shim and Respond.js IE8 support of HTML5 elements and media queries -->
    <!-- WARNING: Respond.js doesn't work if you view the page via file:// -->
    <!--[if lt IE 9]>
        <script src="https://oss.maxcdn.com/libs/html5shiv/3.7.0/html5shiv.js"></script>
        <script src="https://oss.maxcdn.com/libs/respond.js/1.4.2/respond.min.js"></script>
    <![endif]-->

</head>


<body>

    <!-- Navigation -->
<nav class="navbar navbar-default navbar-custom navbar-fixed-top" style="z-index:100">
    <div class="container-fluid">
        <!-- Brand and toggle get grouped for better mobile display -->
        <div class="navbar-header page-scroll">
            <button type="button" class="navbar-toggle" data-toggle="collapse" data-target="#bs-example-navbar-collapse-1">
                <span class="sr-only">Toggle navigation</span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
            </button>
            <a class="navbar-brand" href="/bigdata/">Bigdata Bootcamp</a>
        </div>

        <!-- Collect the nav links, forms, and other content for toggling -->
        <div class="collapse navbar-collapse" id="bs-example-navbar-collapse-1">
            <ul class="nav navbar-nav navbar-right">
<!--                 <li>
                    <a href="/bigdata/">Home</a>
                </li> -->
                <li>
                    <a href="/bigdata/contact/">Contact us</a>
                </li>
<!--                 <li>
                    <a href="/bigdata/spark/">Spark</a>
                </li> -->
<!--                 <li>
                    <a href="/bigdata/hadoop/">Hadoop</a>
                </li> -->
            </ul>
            <ul class="nav navbar-nav navbar-left">
                <li>
                    <a href="/bigdata/">Home</a>
                </li>
<!--                 <li>
                    <a href="/bigdata/about/">About</a>
                </li> -->
                <li>
                    <a href="/bigdata/hadoop/">Hadoop</a>
                </li>
                <li>
                    <a href="/bigdata/spark/">Spark</a>
                </li>
                <li><a href="/bigdata/environment/">Environment</a></li>
                <li><a href="/bigdata/data/">Data</a></li>
            </ul>
        </div>
        <!-- /.navbar-collapse -->
    </div>
    <!-- /.container -->
</nav>


    <!-- Page Header -->
<header class="intro-header" style="background-image: url('/bigdata/image/background.jpg')">
    <div class="container">
        <div class="row">
            <div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1">
                <div class="site-heading" style="padding: 100px 0px 50px 0px">
                    <h1>Hadoop Basic</h1>
                    <hr class="small">
                    <span class="subheading">Georgia Tech big data bootcamp training material</span>
                </div>
            </div>
        </div>
    </div>
</header>

<!-- Main Content -->
<div class="container">
    <div class="row">
        <div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1">
            <ul class="pager">
                
  
  

  
  

  
    
  
  

  
  

  
  

  
  

  
  

  
  

  
  

  
  

  
  

  
  

  
  



<li class="previous">
    <a href="/bigdata/hadoop/" data-toggle="tooltip" data-placement="top" title="Previous Lesson">&larr; Overview of Hadop</a>
</li>

                
  
    
  

  
    
  

  
    
      
    
  

  
    
    
  

  
    
  

  
    
  

  
    
  

  
    
  

  
    
  

  
    
  

  
    
  

  
    
  

  
    
  



<li class="next">
    <a href="/bigdata/hadoop-hbase/" data-toggle="tooltip" data-placement="top" title="Next Lesson">Hadoop HBase&rarr;</a>
</li>


            </ul>

            <div class="bs-callout bs-callout-info" id="callout-helper-context-color-specificity">
        <h4>Learning Objectives</h4><ul>
<li>Being farmiliar with basic operations of HDFS.</li>
<li>Being able to write basic MapReduce program.</li>
</ul>
</div>

<h1 id="hdfs-operations">HDFS Operations</h1>

<p>Hadoop provides a command line utility <code class="prettyprint">hdfs</code> to interact with HDFS. Basic operations are placed under <code class="prettyprint">hdfs dfs</code> subcommand. Let&#39;s play with some basic operations.</p>

<h2 id="create-directory">Create directory</h2>

<p>Similar to creating local directory via linux command <code class="prettyprint">mkdir</code>, creating a folder named <code class="prettyprint">input</code> in HDFS use</p>
<div class="highlight"><pre><code class="language-text" data-lang="text">&gt; hdfs dfs -mkdir input
</code></pre></div>
<p>where <code class="prettyprint">hdfs</code> is the HDFS utility, <code class="prettyprint">dfs</code> is subcommad to handle basic HDFS operation,  <code class="prettyprint">-mkdir</code> means you want to create a directory and directory name is specified as <code class="prettyprint">input</code>. Above command actually create the <code class="prettyprint">input</code> directory in your home directory of HDFS, which by default shold be <code class="prettyprint">/user/your_name/</code>. Of course, you can create it to other place with absolute or relative path.</p>

<h2 id="copy-data-in-and-out">Copy data in and out</h2>

<p>Suppose you followed previous instrucion and created an directory named <code class="prettyprint">input</code>, you can copy data from local file system to HDFS using <code class="prettyprint">-put</code>. For example,</p>
<div class="highlight"><pre><code class="language-text" data-lang="text">&gt; hdfs dfs -put case.csv input
&gt; hdfs dfs -put control.csv input
</code></pre></div>
<p>You can find these two files as described in <a href="/bigdata/data/">sample data</a>.</p>

<p>Corresponds to <code class="prettyprint">-put</code>, <code class="prettyprint">-get</code> operation will copy data out of HDFS. For example</p>
<div class="highlight"><pre><code class="language-text" data-lang="text">hdfs dfs -get input/case.csv local_case.csv
</code></pre></div>
<p>will copy the <code class="prettyprint">input/case.csv</code> file out HDFS into current working directory using a new name <code class="prettyprint">local_case.csv</code>. If you didn&#39;t specify <code class="prettyprint">local_case.csv</code>, the original name <code class="prettyprint">case.csv</code> will be kept.</p>

<h2 id="list-file-information">List File Information</h2>

<p>Just like linux <code class="prettyprint">ls</code> command, <code class="prettyprint">-ls</code> is the operation to list files and folders in HDFS. For example, below command list items in your home directory of HDFS(i.e <code class="prettyprint">/user/your_name/</code>)</p>
<div class="highlight"><pre><code class="language-text" data-lang="text">&gt; hdfs dfs -ls
Found 1 items
-rwxr-xr-x   - hadoop supergroup          0 2015-07-11 06:10 input
</code></pre></div>
<p>You can see the newly created <code class="prettyprint">input</code> directory is listed. You can also see the files inside a particular directory</p>
<div class="highlight"><pre><code class="language-text" data-lang="text">&gt;hdfs dfs -ls input
found 2 items
-rw-r--r--   1 hadoop supergroup     536404 2015-07-11 06:10 input/case.csv
-rw-r--r--   1 hadoop supergroup     672568 2015-07-11 06:08 input/control.csv
</code></pre></div>
<h2 id="fetch-file-content">Fetch file content</h2>

<p>Actually you don&#39;t need to copy file out first to see its content, you can directly use <code class="prettyprint">-cat</code> to printing the content of files in HDFS. For example, below command print out content of the one file you just put into HDFS.</p>
<div class="highlight"><pre><code class="language-text" data-lang="text">hdfs dfs -cat input/case.csv 
</code></pre></div>
<p>You will find wildcard character is very useful since output of MapReduce and other Hadoop based tools tends to be directory. For example, to print content of all csv files(the case.csv and control.csv) in <code class="prettyprint">input</code> HDFS folder, you can</p>
<div class="highlight"><pre><code class="language-text" data-lang="text">hdfs dfs -cat input/*.csv 
</code></pre></div>
<h2 id="further-reading">Further reading</h2>

<p>For more detailed usage of different commands and parameters, you can type</p>
<div class="highlight"><pre><code class="language-text" data-lang="text">hdfs dfs -help
</code></pre></div>
<div class="panel-group exercise">
<div class="panel panel-default">
<div class="panel-heading">
<h4 class="panel-title">
<a data-toggle="collapse" href="#question233" style="text-decoration:none;">Exercise: Remove what you just created.</a>
</h4>
</div>

<div id="question233" class="panel-collapse collapse">
<div class="panel-body">
    <div class="highlight"><pre><code class="language-text" data-lang="text">hdfs dfs -rm -r input
</code></pre></div>
<p>You may miss the <code class="prettyprint">-r</code> option and get error. <code class="prettyprint">-r</code> tells HDFS to remove recursively. This is similar to linux command <code class="prettyprint">rm</code>.</p>
</div></div></div>
</div>

<h1 id="mapreduce">MapReduce</h1>

<p>MapReduce works by breaking the processing into two phases: the map phase and the reduce phase. Each phase has key-value pairs as input and output, the types of which can be chosen by the user. As user, you need to define the <code class="prettyprint">map</code> and <code class="prettyprint">reducer</code> operations.</p>

<p>Let&#39;s write a simple MapReduce program in Java to calculate the frequency of each <code class="prettyprint">event-id</code> in our <strong>case.csv</strong> file described in <a href="/bigdata/data/">sample data</a>.</p>

<p>A MapReduce program consists of three parts:</p>

<ol>
<li>A Mapper Class</li>
<li>A Reducer Class</li>
<li>A main function that tells Hadoop to use the classes we created.</li>
</ol>

<h2 id="mapper">Mapper</h2>

<p>Create a Java file <code class="prettyprint">FrequencyMapper.java</code>. The FrequencyMapper class extends the predefined <code class="prettyprint">Mapper</code> class and overwrite the <code class="prettyprint">map</code> function.</p>
<div class="highlight"><pre><code class="language-java" data-lang="java">import java.io.IOException;

import org.apache.hadoop.io.IntWritable;
import org.apache.hadoop.io.LongWritable;
import org.apache.hadoop.io.Text;
import org.apache.hadoop.mapreduce.Mapper;

public class FrequencyMapper
  extends Mapper&lt;LongWritable, Text, Text, IntWritable&gt; {

  private final static IntWritable one = new IntWritable(1);

  @Override
  public void map(LongWritable offset, Text lineText, Context context)
      throws IOException, InterruptedException {

    String line = lineText.toString();
    String eventID = line.split(&quot;,&quot;)[1];
    context.write(new Text(eventID), one);
  }
}
</code></pre></div>
<p>The 4-tuple <code class="prettyprint">&lt;LongWritable, Text, Text, IntWritable&gt;</code> specifies that the inpur key-value pair is of type <code class="prettyprint">&lt;LongWritable, Text&gt;</code> and the output key-value type is of type <code class="prettyprint">&lt;Text, IntWritable&gt;</code>.
Since the input files are plain text, we use the input key-value pair of type <code class="prettyprint">&lt;LongWritable, Text&gt;</code>. The key is the offset of the start of each line, which is not used here. The value is the actual text in the corresponding line.</p>

<p>We use <code class="prettyprint">toString()</code> to transform the Hadoop <code class="prettyprint">Text</code> object into the more familiar Java <code class="prettyprint">String</code> object and extract only the second field of the line (recall that each line is in the form of <code class="prettyprint">patient-id, event-id, timestamp, value</code>). We then call <code class="prettyprint">context.write</code> to write the output. Each <code class="prettyprint">line</code> will be mapped to a pair as <code class="prettyprint">(event-id, 1)</code>, where 1 is of type IntWritable. Since 1 is a constant, we use a static variable to store it. </p>

<h2 id="reducer">Reducer</h2>

<p>Hadoop internally performs a shuffling process to ensure that the output of the mapper with a same key (same <code class="prettyprint">event-id</code> in our problem) will go to a same reducer. A reducer thus receives a key and a collection of corresponding values (Java <code class="prettyprint">Iterable</code> object). In our case the key-value pair is <code class="prettyprint">(event-id, [1,1,...,1])</code>.</p>

<p>Create a Java file <code class="prettyprint">FrequencyReducer.java</code>. The FrequencyReducer class extends the predefined <code class="prettyprint">Reducer</code> class and overwrite the <code class="prettyprint">reduce</code> function.</p>
<div class="highlight"><pre><code class="language-java" data-lang="java">import java.io.IOException;

import org.apache.hadoop.io.IntWritable;
import org.apache.hadoop.io.Text;
import org.apache.hadoop.mapreduce.Reducer;

public class FrequencyReducer extends Reducer&lt;Text ,  IntWritable ,  Text ,  IntWritable &gt; {
     @Override public void reduce( Text eventID,  Iterable&lt;IntWritable&gt; counts,  Context context)
         throws IOException,  InterruptedException {

      int sum  = 0;
      for ( IntWritable count  : counts) {
        sum  += count.get();
      }
      context.write(eventID,  new IntWritable(sum));
    }
}

</code></pre></div>
<p>The 4-typle <code class="prettyprint">&lt;Text ,  IntWritable ,  Text ,  IntWritable &gt;</code> specifies the types of the input and output key-value pair.
Note that the type of the input key-value pair (<code class="prettyprint">&lt;Text ,  IntWritable&gt;</code>) is the same as the output key-value pair of the mapper.</p>

<h2 id="main-function">Main function</h2>

<p>Write a Java file <code class="prettyprint">Frequency.java</code> that runs the MapReduce job.</p>
<div class="highlight"><pre><code class="language-java" data-lang="java">import org.apache.hadoop.fs.Path;
import org.apache.hadoop.io.IntWritable;
import org.apache.hadoop.io.Text;
import org.apache.hadoop.mapreduce.Job;
import org.apache.hadoop.mapreduce.lib.input.FileInputFormat;
import org.apache.hadoop.mapreduce.lib.output.FileOutputFormat;

public class Frequency {

  public static void main(String[] args) throws Exception {
    if (args.length != 2) {
      System.err.println(&quot;Usage: Frequency &lt;input path&gt; &lt;output path&gt;&quot;);
      System.exit(-1);
    }

    // create a Hadoop job and set the main class
    Job job = Job.getInstance();
    job.setJarByClass(Frequency.class);
    job.setJobName(&quot;Frequency&quot;);

    // set the input and output path
    FileInputFormat.addInputPath(job, new Path(args[0]));
    FileOutputFormat.setOutputPath(job, new Path(args[1]));

    // set the Mapper and Reducer class
    job.setMapperClass(FrequencyMapper.class);
    job.setReducerClass(FrequencyReducer.class);

    // specify the type of the output
    job.setOutputKeyClass(Text.class);
    job.setOutputValueClass(IntWritable.class);

    // run the job
    System.exit(job.waitForCompletion(true) ? 0 : 1);
  }
}
</code></pre></div>
<h2 id="compile-and-run">Compile and Run</h2>

<p>You can find all source code in <code class="prettyprint">sample/hadoop</code> folder. You will need to navigate to that folder first, then compile, creat jar and run.</p>

<h3 id="compile">Compile</h3>

<p>Compile the three java files with <code class="prettyprint">javac</code></p>
<div class="highlight"><pre><code class="language-text" data-lang="text">javac -cp $(hadoop classpath) -d Frequency FrequencyMapper.java FrequencyReducer.java Frequency.java 
</code></pre></div>
<p>where <code class="prettyprint">hadoop classpath</code> outputs the required class path to compile a Hadoop program. <code class="prettyprint">-d classes</code> puts the generated classes into the <code class="prettyprint">classes</code> directory. You will  see three class files in the <code class="prettyprint">classes</code> directory now.</p>

<h3 id="create-jar">Create JAR</h3>

<p>Let&#39;s create a jar named <code class="prettyprint">Frequency.jar</code> using classes we just compiled.</p>
<div class="highlight"><pre><code class="language-text" data-lang="text">jar -cvf Frequency.jar -C classes/ .
</code></pre></div>
<div class="msgbox bg-info"><h4>Information</h4><p>In real world application development, you will not need to compile files manually one by one then create jar. Instead, build tools like Maven, Gradle, SBT will be employed.</p>
</div>

<h3 id="run">Run</h3>

<p>You can run the jar file just created with</p>
<div class="highlight"><pre><code class="language-text" data-lang="text">hadoop jar Frequency.jar Frequency input output
</code></pre></div>
<p>where <code class="prettyprint">Frequency.jar</code> is named of jar file, <code class="prettyprint">Frequency</code> is java class to run. <code class="prettyprint">input</code> and <code class="prettyprint">output</code> are parameters to the <code class="prettyprint">Frequency</code> class we implemented. Please be careful that <code class="prettyprint">input</code> and <code class="prettyprint">output</code> are used as path in HDFS.</p>

<p>While the program is running, you will see a lot of messages. After the job finishes, you can check the results in the <code class="prettyprint">output</code> directory (created by Hadoop) by </p>
<div class="highlight"><pre><code class="language-text" data-lang="text">hdfs dfs -ls output
hdfs dfs -cat output/*
</code></pre></div>
<p>You will get results like</p>
<div class="highlight"><pre><code class="language-text" data-lang="text">DIAG03812       2
DIAG03819       1
DIAG0420        1
DIAG0539        2
DIAG05443       1
DIAG06640       1
DIAG07032       1
DIAG1120        5
...
</code></pre></div>
<p>Please notice that the output content order may be different from above.</p>

<h3 id="clean-up">Clean up</h3>

<p>If you run the job again, you will see an error message saying the <code class="prettyprint">output</code> directory already exists. This prevents a user to accidentally overwrite a file. You can remove the directory by</p>
<div class="highlight"><pre><code class="language-text" data-lang="text">hdfs dfs -rm -r output
</code></pre></div>
<div class="panel-group exercise">
<div class="panel panel-default">
<div class="panel-heading">
<h4 class="panel-title">
<a data-toggle="collapse" href="#question234" style="text-decoration:none;">Exercise: Count diagnostic code only(events start with DIAG).</a>
</h4>
</div>

<div id="question234" class="panel-collapse collapse">
<div class="panel-body">
    <p>You can achieve this by updating mapper as</p>
<div class="highlight"><pre><code class="language-java" data-lang="java">public void map(LongWritable offset, Text lineText, Context context)
    throws IOException, InterruptedException {
  String line = lineText.toString();
  String eventID = line.split(&quot;,&quot;)[1];
  if(eventID.startsWith(&quot;DIAG&quot;)){
    context.write(new Text(eventID), one);
  }
}
</code></pre></div>
</div></div></div>
</div>


            <ul class="pager">
                
  
  

  
  

  
    
  
  

  
  

  
  

  
  

  
  

  
  

  
  

  
  

  
  

  
  

  
  



<li class="previous">
    <a href="/bigdata/hadoop/" data-toggle="tooltip" data-placement="top" title="Previous Lesson">&larr; Overview of Hadop</a>
</li>

                
  
    
  

  
    
  

  
    
      
    
  

  
    
    
  

  
    
  

  
    
  

  
    
  

  
    
  

  
    
  

  
    
  

  
    
  

  
    
  

  
    
  



<li class="next">
    <a href="/bigdata/hadoop-hbase/" data-toggle="tooltip" data-placement="top" title="Next Lesson">Hadoop HBase&rarr;</a>
</li>


            </ul>

            <div class="clearfix"></div>

            <hr>
            <!-- disqus -->
            <div id="disqus_thread"></div>
            <script type="text/javascript">
                /* * * CONFIGURATION VARIABLES * * */
                var disqus_shortname = 'sunlabbigdata';
                
                /* * * DON'T EDIT BELOW THIS LINE * * */
                (function() {
                    var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
                    dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
                    (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
                })();
            </script>
            <noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript" rel="nofollow">comments powered by Disqus.</a></noscript>
        </div>
        <div class="col-lg-2 col-md-1">
            <div id="toc"></div>
        </div>
    </div>
</div>

<hr>



    <!-- Footer -->
<footer>
    <div class="container">
        <div class="row">
            <div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1">
                <ul class="list-inline text-center">
                    <li>
                        <a href="/bigdata/feed.xml" target="_blank">
                            <span class="fa-stack fa-lg">
                                <i class="fa fa-circle fa-stack-2x"></i>
                                <i class="fa fa-rss fa-stack-1x fa-inverse"></i>
                            </span>
                        </a>
                    </li>
                    
                    <li>
                        <a href="https://twitter.com/jimeng" target="_blank">
                            <span class="fa-stack fa-lg">
                                <i class="fa fa-circle fa-stack-2x"></i>
                                <i class="fa fa-twitter fa-stack-1x fa-inverse"></i>
                            </span>
                        </a>
                    </li>
                    
                    
                    <li>
                        <a href="https://www.facebook.com/cmanul" target="_blank">
                            <span class="fa-stack fa-lg">
                                <i class="fa fa-circle fa-stack-2x"></i>
                                <i class="fa fa-facebook fa-stack-1x fa-inverse"></i>
                            </span>
                        </a>
                    </li>
                    
                    
                    <li>
                        <a href="https://github.com/cmanul" target="_blank">
                            <span class="fa-stack fa-lg">
                                <i class="fa fa-circle fa-stack-2x"></i>
                                <i class="fa fa-github fa-stack-1x fa-inverse"></i>
                            </span>
                        </a>
                    </li>
                    
                </ul>
                <p class="copyright text-muted">Copyright &copy; Georgia Institute of Technology 2015. Theme by <a href="https://github.com/IronSummitMedia/startbootstrap-clean-blog-jekyll" target="_blank">Iron Summit Media</a>'s Jekyll version of <a href="http://startbootstrap.com/template-overviews/clean-blog/" target="_blank">Clean Blog</a>.</p>
            </div>
        </div>
    </div>
</footer>

<!-- jQuery -->
<script src="/bigdata/js/jquery.min.js "></script>

<!-- Bootstrap Core JavaScript -->
<script src="/bigdata/js/bootstrap.min.js "></script>

<!-- TOC -->
<script src="/bigdata/js/jquery-ui.min.js"></script>
<script src="/bigdata/js/jquery.tocify.js"></script>

<!-- ACE Editor -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/ace/1.2.0/ace.js" type="text/javascript" charset="utf-8"></script>

<!-- Custom Theme JavaScript -->
<script src="/bigdata/js/bigdata-bootcamp.js "></script>


</body>

</html>
